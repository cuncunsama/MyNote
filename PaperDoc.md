## DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation (CVPR2023)
*<https://ieeexplore.ieee.org/document/10204880/authors#authors>*  
*<https://dreambooth.github.io>* 

**Problem**  
Large text-to-text models cannot mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts.  

The diffusion models slowly forgets how to generate subjects of the same class as the target subject.  

Text-to-image diffusion models naturally posses high amounts of output diversity. There is a risk of reducing the amount of variability in the output poses and views of the subject when fine-tuning on a small set of images.

*language drift*  

**Effect** The effect is akin to a “magic photo booth”—once a few images of the subject are taken, the booth generates photos of the subject in different conditions and scenes, as guided by simple and intuitive text prompts.

## Learning Transferable Visual Models From Natural Language Supervision(CLIP)
*<https://openai.com/research/clip>*
*<https://arxiv.org/abs/2103.00020>*
*<https://github.com/openai/CLIP>*


